{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "def dataset_preparation(data):\n",
    "\n",
    "\t# basic cleanup\n",
    "\tcorpus = data.lower().split(\"\\n\")\n",
    "\n",
    "\t# tokenization\t\n",
    "\ttokenizer.fit_on_texts(corpus)\n",
    "\ttotal_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "\t# create input sequences using list of tokens\n",
    "\tinput_sequences = []\n",
    "\tfor line in corpus:\n",
    "\t\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\t\tfor i in range(1, len(token_list)):\n",
    "\t\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "\t# pad sequences \n",
    "\tmax_sequence_len = max([len(x) for x in input_sequences])\n",
    "\tinput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "\t# create predictors and label\n",
    "\tpredictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\tlabel = ku.to_categorical(label, num_classes=total_words)\n",
    "\n",
    "\treturn predictors, label, max_sequence_len, total_words\n",
    "\n",
    "def create_model(predictors, label, max_sequence_len, total_words):\n",
    "\t\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n",
    "\tmodel.add(LSTM(150))\n",
    "\t# model.add(Dropout(0.2))\n",
    "# \tmodel.add(LSTM(100))\n",
    "\tmodel.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\tearlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "\tmodel.fit(predictors, label, epochs=10, verbose=1, callbacks=[earlystop])\n",
    "\tprint(model.summary())\n",
    "\treturn model \n",
    "                                  \n",
    "def generate_text(seed_text, next_words, max_sequence_len):\n",
    "\tfor _ in range(next_words):\n",
    "\t\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\t\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\t\tpredicted = model.predict_classes(token_list, verbose=0)\n",
    "\t\t\n",
    "\t\toutput_word = \"\"\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == predicted:\n",
    "\t\t\t\toutput_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\tseed_text += \" \" + output_word\n",
    "\treturn seed_text\n",
    "\n",
    "\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='r', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "data = load_doc('hindi_small_concat.txt')\n",
    "\n",
    "predictors, label, max_sequence_len, total_words = dataset_preparation(data)\n",
    "model = create_model(predictors, label, max_sequence_len, total_words)\n",
    "print(generate_text(\"we naughty\", 3, max_sequence_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boys cat and and\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"boys\", 3, max_sequence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
