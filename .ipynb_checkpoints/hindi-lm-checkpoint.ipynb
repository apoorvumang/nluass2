{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array\n",
    "import nltk\n",
    "\n",
    "# threshold for minimum count to be considered a valid word\n",
    "MIN_VOCAB_COUNT = 3\n",
    "OOV_TOKEN = \"UNK\"\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='r', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# remove numbers. they can be like 100 1090,200 2.123 etc\n",
    "# strategy is to remove punctuation and then check if its an integer\n",
    "def isNumber(word):\n",
    "    word_no_num = re.sub(r'[^\\w\\s]','',word)\n",
    "    if RepresentsInt(word_no_num):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#tokenizes raw strings\n",
    "def getTokenized(lines):\n",
    "    exclude = set(string.punctuation)\n",
    "    exclude.add('-')\n",
    "    exclude.add('।')\n",
    "    words_list = [] \n",
    "    total_sent = len(lines)\n",
    "    n = 0\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        words = nltk.word_tokenize(line)\n",
    "        words_nopunc_nonum = []\n",
    "        for word in words:\n",
    "            if word in exclude: # if punctuation\n",
    "                continue\n",
    "            else:\n",
    "                word = word.replace('।', '')\n",
    "                if(isNumber(word)): # if number\n",
    "                    word = \"NUMBER\"\n",
    "                words_nopunc_nonum.append(word)\n",
    "#         if(len(words_nopunc_nonum) >= 1):\n",
    "#             words_nopunc_nonum[-1] = words_nopunc_nonum[-1].replace('।', '')\n",
    "        words_list.append(words_nopunc_nonum)\n",
    "        if(n%10000 == 0):\n",
    "            print((n/total_sent)*100.0, '% done')\n",
    "        n+= 1\n",
    "    return words_list\n",
    "\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "\n",
    "def getVocabulary(tokenized_corpus):\n",
    "    vocabulary = {}\n",
    "    total_sent = len(tokenized_corpus)\n",
    "    n = 0\n",
    "    for sentence in tokenized_corpus:\n",
    "        for token in sentence:\n",
    "            if token not in vocabulary:\n",
    "                vocabulary[token] = 1\n",
    "            else:\n",
    "                vocabulary[token] += 1\n",
    "        if(n%10000 == 0):\n",
    "            print((n/total_sent)*100.0, '% done')\n",
    "        n+= 1\n",
    "    new_dict = {}\n",
    "    oov_count = 0 \n",
    "    # remove infrequent words\n",
    "    for word, count in vocabulary.items():\n",
    "        if(count >= MIN_VOCAB_COUNT):\n",
    "            new_dict[word] = count\n",
    "        else:\n",
    "            oov_count += count\n",
    "    new_dict[OOV_TOKEN] = oov_count\n",
    "    word2id = {w: idx for (idx, w) in enumerate(new_dict)}\n",
    "    id2word = {idx: w for (idx, w) in enumerate(new_dict)}\n",
    "    return new_dict, word2id, id2word\n",
    "\n",
    "def removeOOV(sentences, vocab):\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        new_sent = []\n",
    "        for word in sentence:\n",
    "            if word in vocab:\n",
    "                new_sent.append(word)\n",
    "            else:\n",
    "                new_sent.append(OOV_TOKEN)\n",
    "        new_sentences.append(new_sent)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = load_doc('data/hindi/hindmonocorp05.plaintext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4359377142"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hwt2013\\t<s>\\tलेकिन गांव के जगदीश मेघवाल, मोहन...\\nspiderling\\t<s>\\tविटामिन सी शरीर में रोग पैदा करने वाल'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi = hindi[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = hindi.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44486483"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['लेकिन गांव के जगदीश मेघवाल, मोहन...',\n",
       " 'विटामिन सी शरीर में रोग पैदा करने वाले विषाणुओं से लड़ने की ताकत पैदा करता है और शरीर में इसकी संतुलित मात्रा बने रहने से रोग प्रतिरोधक क्षमता मजबूत रहती है।',\n",
       " 'इन बोतलों के बहुत कम पैसे मिलते हैं।',\n",
       " 'कार्टून :- रे लोकपाल आ गया तू ? शाबाश.... 19 0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = []\n",
    "for line in sentences:\n",
    "    tokens = line.split('\\t')\n",
    "    if len(tokens) >= 3:\n",
    "        new_sentences.append(tokens[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'इन दिनों उसी जमीन पर काम चल रहा है।'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentences[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = new_sentences\n",
    "small = sentences[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % done\n",
      "10.0 % done\n",
      "20.0 % done\n",
      "30.0 % done\n",
      "40.0 % done\n",
      "50.0 % done\n",
      "60.0 % done\n",
      "70.0 % done\n",
      "80.0 % done\n",
      "90.0 % done\n"
     ]
    }
   ],
   "source": [
    "tokenized_hindi = getTokenized(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'भारी हिमपात के समय यहां पर 2 फीट बर्फ की मोटी परत जम जाती है।'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('hindi_small.txt', \"wb\")\n",
    "for line in small:\n",
    "    string_for_output = (line + '\\n').encode('utf8', 'replace')\n",
    "    fw.write(string_for_output)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'किया'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = tokenized_hindi[1010][-1]\n",
    "word\n",
    "# word.replace('।', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % done\n",
      "10.0 % done\n",
      "20.0 % done\n",
      "30.0 % done\n",
      "40.0 % done\n",
      "50.0 % done\n",
      "60.0 % done\n",
      "70.0 % done\n",
      "80.0 % done\n",
      "90.0 % done\n"
     ]
    }
   ],
   "source": [
    "vocabulary, word2id, id2word = getVocabulary(tokenized_hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27625"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_hindi = removeOOV(tokenized_hindi, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "पारायण\n",
      "डीएनए\n",
      "रजिस्ट्री\n",
      "पुडिया\n",
      "आपूर्ति\n",
      "मनुष्यों\n",
      "छील\n",
      "परतंत्रता\n",
      "कर्मवीर\n",
      "दरगाह\n",
      "दयावती\n",
      "सटाकर\n",
      "एक्सपो\n",
      "ग्रेट\n",
      "एंट्री\n",
      "दर्पण\n",
      "are\n",
      "चकत्ते\n",
      "जनतंत्र\n",
      "अरहर\n",
      "रहूँ\n",
      "कलकत्ते\n",
      "ओक\n",
      "पण\n",
      "कृष्णमूर्ति\n",
      "जरूरतमंद\n",
      "10वीं\n",
      "इंडियन\n",
      "पढाया\n",
      "प्रभागीय\n",
      "मात\n",
      "ज्ञाता\n",
      "हज़ार\n",
      "सुनी\n",
      "तरीको\n",
      "नाई\n",
      "हाउ\n",
      "तमाचा\n",
      "मुर्गियों\n",
      "रक्षण\n",
      "सीएसएस\n",
      "शक्तिपीठ\n",
      "शराफत\n",
      "तमे\n",
      "उभरी\n",
      "कैसेट\n",
      "ब्लॉगजगत\n",
      "आसार\n",
      "हाईवे\n",
      "पहुंचाता\n",
      "अंधा\n",
      "बदतर\n",
      "पीटे\n",
      "पश्च\n",
      "संघों\n",
      "चढ़ाये\n",
      "देवरिया\n",
      "रोगाणु\n",
      "इरशाद\n",
      "कारें\n",
      "चहुँ\n",
      "महिने\n",
      "स्त्रोतों\n",
      "प्रतिबिम्बित\n",
      "शोभायात्रा\n",
      "सुधरेगी\n",
      "लेना-देना\n",
      "भईया\n",
      "बचेगा\n",
      "शृंखलाओं\n",
      "रखती\n",
      "चिंतन\n",
      "मजे\n",
      "रत्ती\n",
      "चोटियां\n",
      "नवाबों\n",
      "विष\n",
      "उड़ीसा\n",
      "योगा\n",
      "टाँग\n",
      "सब्जियां\n",
      "सीमाएँ\n",
      "बालाओं\n",
      "प्रतीति\n",
      "कृतियां\n",
      "रसखानि\n",
      "राजकपूर\n",
      "बढावा\n",
      "फ़िल्टर्ड\n",
      "कालेजों\n",
      "गवाहों\n",
      "बर्तनों\n",
      "सीवान\n",
      "उपायों\n",
      "एकतरफ़ा\n",
      "डोगरी\n",
      "कुचलने\n",
      "उत्तर-\n",
      "रघुवीर\n",
      "दुर्बल\n",
      "बनवा\n",
      "भरना\n",
      "टालते\n",
      "हुयी\n",
      "तुम्हीं\n",
      "लटकाने\n",
      "मक\n",
      "चित्त\n",
      "मन्तर\n",
      "शीश\n",
      "चमकीले\n",
      "एकांश\n",
      "वस्तुयें\n",
      "मुर्दा\n",
      "पीसते\n",
      "जमीन-जायदाद\n",
      "इकाइयां\n",
      "साबला\n",
      "आंच\n",
      "लागि\n",
      "अवैज्ञानिक\n",
      "व्यक्त\n",
      "अधेड़\n",
      "कलंक\n",
      "बिगाड़ना\n",
      "दीपदान\n",
      "फंसा\n",
      "धनबाद\n",
      "अमरीकी\n",
      "घबराने\n",
      "यंग्\n",
      "जनजाति\n",
      "पडता\n",
      "गुनगुनाते\n",
      "चौरा\n",
      "सम्मानों\n",
      "नदारद\n",
      "चीन\n",
      "प्रौद्योगिकियों\n",
      "पकड़ती\n",
      "बारे\n",
      "छाती\n",
      "एक-डेढ़\n",
      "मेंरे\n",
      "डि\n",
      "स्थानांतरित\n",
      "वॉशिंगटन\n",
      "हटाई\n",
      "जगाये\n",
      "अंकल\n",
      "जायगा\n",
      "सौदागर\n",
      "रवाना\n",
      "स्कुल\n",
      "बहुधा\n",
      "ला\n",
      "अर्थशास्त्रियों\n",
      "उल्टी\n",
      "मार्गदर्शिका\n",
      "मौजूदगी\n",
      "अजा\n",
      "महाबोधि\n",
      "पावडर\n",
      "उत्पादों\n",
      "क़दर\n",
      "संगति\n",
      "सशक्त\n",
      "आगाह\n",
      "गुरूजी\n",
      "काहे\n",
      ".पता\n",
      "रूमाल\n",
      "दायित्\n",
      "कण\n",
      "अक्षुण्ण\n",
      "रिलैक्स\n",
      "बढ़ना\n",
      "आंदोलित\n",
      "सांस\n",
      "नवीनतम\n",
      "बनाईये\n",
      "गटर\n",
      "though\n",
      "दीखा\n",
      "कल्याणी\n",
      "अवसर\n",
      "रिहाई\n",
      "कहाँ\n",
      "ठानी\n",
      "प्रमाणों\n",
      "हिन्दू-मुस्लिम\n",
      "मिशन\n",
      "कतार\n",
      "बाघों\n",
      "ओंकारेश्वर\n",
      "सीसीटीवी\n",
      "सम्भवतः\n",
      "कश्ती\n",
      "जयललिता\n",
      "अशरफ\n",
      "पागलपन\n",
      "दुपट्टे\n",
      "केपिटल\n",
      "बजी\n",
      "साम्राज्यवादी\n",
      "घुमाकर\n",
      "राजप्रमुख\n",
      "तोमर\n",
      "डेविस\n",
      "मोइली\n",
      "डूबने\n",
      "ख़ुद\n",
      "चिल्लाओ\n",
      "इत्तेफाक\n",
      "साग\n",
      "डेली\n",
      "बोक्सिंग\n",
      "पिलाते\n",
      "सवारियां\n",
      "उम्मीद\n",
      "गायकी\n",
      "ट्रेनर\n",
      "कीं\n",
      "निकटस्थ\n",
      "उतने\n",
      "मार्गदर्शक\n",
      "नक्शे\n",
      "जहरीला\n",
      "पले\n",
      "समीक्षा\n",
      "दुनियादारी\n",
      "थामते\n",
      "गुरप्रीत\n",
      "लेखापरीक्षा\n",
      "दैत्यराज\n",
      "आबू\n",
      "आपेक्षा\n",
      "बारात\n",
      "विद्युत\n",
      "राज्यों\n",
      "कार्यकाल\n",
      "अजीज\n",
      "ढहने\n",
      "शैव\n",
      "गोपालसिंह\n",
      "इंकार\n",
      "चमत्कृत\n",
      "श्रद्धांजली\n",
      "अवधिया\n",
      "दीर्घ\n",
      "ज्वाला\n",
      "धावा\n",
      "प्रबन्धक\n",
      "टार्च\n",
      "क्यूंकि\n",
      "रोकिये\n",
      "डरपोक\n",
      "ऊर्जा\n",
      "दूसरा\n",
      "हैँ\n",
      "मित्रवत\n",
      "रूठ\n",
      "जनसंख्या\n",
      "प्रचलन\n",
      "लीज\n",
      "वजहें\n",
      "सीमाओं\n",
      "नॉमिनी\n",
      "ग्रीनहाउस\n",
      "शायरों\n",
      "धीमा\n",
      "बिज़ी\n",
      "हाई\n",
      "परवाह\n",
      "संभवतः\n",
      "कस्टम\n",
      "झुलस\n",
      "पटखनी\n",
      "म्युनिसिपल\n",
      "पढाते\n",
      "श्रृंखला\n",
      "इंद्रा\n",
      "तैरती\n",
      "रूचि\n",
      "शुष्क\n",
      "शमशाद\n",
      "मालामाल\n",
      "त्रिकोणीय\n",
      "शर्मिंदगी\n",
      "दौड़ा\n",
      "निर्भीकता\n",
      "सन्नी\n",
      "देवानंद\n",
      "सिवान\n",
      "चक्\n",
      "लदी\n",
      "पांडिचेरी\n",
      "सैल्यूट\n",
      "जैम\n",
      "आजमगढ़\n",
      "झाडू\n",
      "अभिमान\n",
      "टाइम्\n",
      "लेखक\n",
      "बिलासपुर\n",
      "वायरस\n",
      "भवन\n",
      "घोड़ी\n",
      "सौगंध\n",
      "निलयम\n",
      "यासीन\n",
      "मेहनताना\n",
      "अपनाना\n",
      "इंडियंस\n",
      "-श्री\n",
      "बाहों\n",
      "चमेली\n",
      "लहरें\n",
      "पवित्र\n",
      "हुक\n",
      "ससेक्स\n",
      "छेड़खानी\n",
      "all\n",
      "दमक\n",
      "कण-कण\n",
      "जता\n",
      "समग्र\n",
      "page\n",
      "पडते\n",
      "प्रलाप\n",
      "जटिलताओं\n",
      "दिखेंगे\n",
      "प्राधिकार\n",
      "ाी\n",
      "सुधारना\n",
      "सांसें\n",
      "बधाई\n",
      "सॉसद\n",
      "माधुर्य\n",
      "बंदरगाह\n",
      "लड़ते\n",
      "दुबई\n",
      "हिस्से\n",
      "न्यासी\n",
      "उत्पादन\n",
      "नोटबुक\n",
      "इनपुट\n",
      "जोड़े\n",
      "तरसेम\n",
      "परमेश्वर\n",
      "उवाच\n",
      "औरंगज़ेब\n",
      "बंधुआ\n",
      "तुर्रा\n",
      "दंतेवाड़ा\n",
      "पहुंचायी\n",
      "moon\n",
      "रक्तस्त्राव\n",
      "सुख-दुःख\n",
      "अनेकों\n",
      "बढ़ोत्तरी\n",
      "धमकाया\n",
      "निर्देशिका\n",
      "दाँतों\n",
      "रेबीज\n",
      "लड़ाकू\n",
      "ग्रंथों\n",
      "रनों\n",
      "धनिया\n",
      "आगाज़\n",
      "सही\n",
      "जनपद\n",
      "निपटान\n",
      "संयुक्त\n",
      "धाम\n",
      "बोस\n",
      "इलाकों\n",
      "दूरियों\n",
      "सरेआम\n",
      "शासक\n",
      "देहरी\n",
      "चोटियाँ\n",
      "गैरों\n",
      "खींचना\n",
      "देवालय\n",
      "रियाज\n",
      "गवर्नमेंट\n",
      "एविएशन\n",
      "चंद्रकांत\n",
      "चेयर\n",
      "विभूतियों\n",
      "भगाना\n",
      "टूक\n",
      "अड्डों\n",
      "Oct\n",
      "संबंध\n",
      "सुगबुगाहट\n",
      "विरोधाभास\n",
      "ड्रॉ\n",
      "कैबिनेट\n",
      "प्रजातंत्र\n",
      "थ\n",
      "पते\n",
      "परिणाम\n",
      "इटालियन\n",
      "संग्रहालयों\n",
      "खड़ा\n",
      "ढाक\n",
      "प्यारा\n",
      "तख्ते\n",
      "दुखने\n",
      "अदह\n",
      "सबेर\n",
      "अँधेरा\n",
      "चली\n",
      "अर्जित\n",
      "गुंजायमान\n",
      "नटवर\n",
      "केन्द्रों\n",
      "कंधे\n",
      "चीफ़\n",
      "साफ-सफाई\n",
      "अनुशंसा\n",
      "नाथद्वारा\n",
      "गोपियाँ\n",
      "निमित्त\n",
      "बंधू\n",
      "अंडरवियर\n",
      "फैल\n",
      "गोबर\n",
      "चयनकर्ता\n",
      "पेशवा\n",
      "स्मारकों\n",
      "उच्चायुक्त\n",
      "करूणा\n",
      "बाल्यावस्था\n",
      "पूजने\n",
      "जरूर\n",
      "सुपरकिंग्स\n",
      "तकरार\n",
      "मंशा\n",
      "डिफाल्टर\n",
      "फॉरेस्ट\n",
      "साक्षात्\n",
      "अराबुल\n",
      "कोर\n",
      "नुमाइंदगी\n",
      "भुट्टे\n",
      "सांस्कृतिक\n",
      "मेमने\n",
      "ताला\n",
      "ओझा\n",
      "पीना\n",
      "दाभोलकर\n",
      "लम्बाई\n",
      "प्रविष्टियाँ\n",
      "सालती\n",
      "न्यूनतम\n",
      "आलुओं\n",
      "होमर\n",
      "धुरी\n",
      "बनानी\n",
      "मज़ेदार\n",
      "ढूंढने\n",
      "गार्जियन\n",
      "जबाव\n",
      "मौलिक\n",
      "م\n",
      "नोटों\n",
      "एपिसोड\n",
      "पैनेपन\n",
      "मति\n",
      "मचता\n",
      "आनुपातिक\n",
      "ब्लास्ट\n",
      "केरी\n",
      "रंगे\n",
      "मिसिरजी\n",
      "बुखार\n",
      "मुड\n",
      "शाहबानो\n",
      "डरते-डरते\n",
      "कद\n",
      "मोटी\n",
      "आऊँगा\n",
      "लाग\n",
      "दिन\n",
      "आहिस्ता-आहिस्ता\n",
      "लगने\n",
      "मान्य\n",
      "मोडरेशन\n",
      "पूर्वी\n",
      "यथा\n",
      "सहभागी\n",
      "लिटा\n",
      "ध्रुव\n",
      "उलझा\n",
      "डालते\n",
      "राइडर्स\n",
      "जीया\n",
      "साक्ष्य\n",
      "ओ.\n",
      "जायदाद\n",
      "पटल\n",
      "समाप्\n",
      "बाइकर्स\n",
      "रहने\n",
      "बढ़ीं\n",
      "करंट\n",
      "फ़तवा\n",
      "हुऐ\n",
      "समझाते\n",
      "जीआरपी\n",
      "रोवर\n",
      "शुल्क\n",
      "तकलीफ़\n",
      "नास्तिक\n",
      "भूलभुलैया\n",
      "कुलसचिव\n",
      "आलेख\n",
      "पदोन्नत\n",
      "देशों\n",
      "गणना\n",
      "कोरस\n",
      "many\n",
      "भोजपुर\n",
      "होटलों\n",
      "बुलाती\n",
      "छह\n",
      "भारतवासियों\n",
      "बढी\n",
      "आशंकाओं\n",
      "जुगलबंदी\n",
      "अपारदर्शी\n",
      "चाहतीं\n",
      "रायपुर\n",
      "हुड़दंग\n",
      "भाग\n",
      "नारों\n",
      "क्रीडा\n",
      "IQ\n",
      "पीढियां\n",
      "चाकू\n",
      "भूसा\n",
      "अधिकता\n",
      "आखेट\n",
      "वरीय\n",
      "भक्\n",
      "हॉल\n",
      "पसारे\n",
      "चमकता\n",
      "दरिद्र\n",
      "शहिद\n",
      "उभरकर\n",
      "समायोजन\n",
      "गोपनीयता\n",
      "आवाज\n",
      "ममतामयी\n",
      "सों\n",
      "शाहरुख़\n",
      "ू\n",
      "नेपाल\n",
      "अफवाहों\n",
      "दोनों\n",
      "सगर\n",
      "हरेपन\n",
      "मोहाली\n",
      "इलाही\n",
      "पीटने\n",
      "बुल्गारिया\n",
      "धूप\n",
      "उगता\n",
      "छुआ\n",
      "प्रदर्शनों\n",
      "बोने\n",
      "कोलावेरी\n",
      "मुम्बई\n",
      "प्रकृति\n",
      "कोलंबो\n",
      "पराबैंगनी\n",
      "लेटते\n",
      "पुछा\n",
      "िखर\n",
      "निलंबन\n",
      "ऑफीसर\n",
      "शिकंजा\n",
      "चटपटा\n",
      "अनार\n",
      "सह-अस्तित्व\n",
      "पापाजी\n",
      "भेल\n",
      "किरायों\n",
      "झटकों\n",
      "स्वीकार्य\n",
      "मूल्यांकन\n",
      "नेविगेटर\n",
      "उन्होंनें\n",
      "बाघ\n",
      "साझा\n",
      "लौंग\n",
      "पढता\n",
      "शाट\n",
      "याज्ञवल्क्य\n",
      "आलोचनाएँ\n",
      "यंग\n",
      "दौड़ती\n",
      "चोटें\n",
      "विक्की\n",
      "दरिन्दों\n",
      "आयी\n",
      "इंटेलिजेंस\n",
      "मुश्ताक\n",
      "एम.ए\n",
      "एमजी\n",
      "फेरा\n",
      "इंडी\n",
      "पदस्थापन\n",
      "आयुक्त\n",
      "सीधा-सादा\n",
      "रज़ा\n",
      "ek\n",
      "एसडीएम\n",
      "अतिक्रमणकारी\n",
      "जिन्\n",
      "हॉकी\n",
      "रौद्र\n",
      "करीबियों\n",
      "ड्राइंग\n",
      "दीखता\n",
      "रहना\n",
      "ज़मीनी\n",
      "निभाना\n",
      "महोत्सव\n",
      "सटे\n",
      "फाइलों\n",
      "जनसंघ\n",
      "नै\n",
      "चिट्टी\n",
      "जीवों\n",
      "प्रभाग\n",
      "आरक्षित\n",
      "काव्यधारा\n",
      "जमाल\n",
      "द्रवित\n",
      "ख़िदमत\n",
      "इसपर\n",
      "कड़ियाँ\n",
      "आईएफएस\n",
      "जनआंदोलन\n",
      "सेतुसमुद्रम\n",
      "विचार-विमर्श\n",
      "पुचकारने\n",
      "shampoo\n",
      "वार्न\n",
      "भड़के\n",
      "«\n",
      "रोमांचकारी\n",
      "खुली\n",
      "पुख्ता\n",
      "माइक्रोमैक्स\n",
      "साहिर\n",
      "उल्लेखनीय\n",
      "जावा\n",
      "सपनो\n",
      "पहचानती\n",
      "साम्यवाद\n",
      "वेश्या\n",
      "स्पाइस\n",
      "रॉय\n",
      "अडवाणी\n",
      "तिरुवनंतपुरम\n",
      "विद्रोही\n",
      "चाहूँगा\n",
      "कंज्यूमर\n",
      "परिणति\n",
      "लेखको\n",
      "इसलिये\n",
      "रोनी\n",
      "ग्लासगो\n",
      "प्रतिबिम्ब\n",
      "जायज़\n",
      "रखूंगा\n",
      "कड़े\n",
      "लौटाई\n",
      "अभय\n",
      "सहेज\n",
      "वक्तव्यों\n",
      "तकरीबन\n",
      "क्लासरूम\n",
      "सिडनी\n",
      "सफ़लता\n",
      "जलाता\n",
      "अठन्नी\n",
      "दीपों\n",
      "हैरिस\n",
      "एमसीडी\n",
      "कश्यप\n",
      "भुट्टो\n",
      "लाभकारी\n",
      "आदर्शों\n",
      "दासता\n",
      "पे\n",
      "शरत\n",
      "डीएवी\n",
      "Microsoft\n",
      "प्रत्याशियों\n",
      "शृंगार\n",
      "उल्टियां\n",
      "बहाल\n",
      "माहेला\n",
      "न्यायलय\n",
      "वासना\n",
      "सक्षम\n",
      "धड़कनों\n",
      "थलीसैंण\n",
      "महत्ता\n",
      "पदक\n",
      "कोल्हान\n",
      "तक़रीबन\n",
      "महसूस\n",
      "सम्प्रदाय\n",
      "अमावस्या\n",
      "तिलहन\n",
      "पसर\n",
      "कविता-संग्रह\n",
      "मरो\n",
      "अराजक\n",
      "अमानवीय\n",
      "बमुश्किल\n",
      "मरद\n",
      "जहाज\n",
      "बनती\n",
      "नही\n",
      "अटेंड\n",
      "उत्तर-पश्चिम\n",
      "लचीले\n",
      "भगदड़\n",
      "सील\n",
      "बैतूल\n",
      "भ\n",
      "सानी\n",
      "बिछौना\n",
      "इंडस्ट्रियल\n",
      "सम्मत\n",
      "ससुरी\n",
      "फैंसी\n",
      "सांस्\n",
      "तात्पर्य\n",
      "लार्सन\n",
      "प्रयत्न\n",
      "टीटी\n",
      "गुमराह\n",
      "विकराल\n",
      "आदान-प्रदान\n",
      "भ्रष्टाचारी\n",
      "युति\n",
      "हैक\n",
      "पहनाकर\n",
      "बेजा\n",
      "चांदी\n",
      "विमुख\n",
      "रामदास\n",
      "रचित\n",
      "दोहरे\n",
      "चुकानी\n",
      "अम्बार\n",
      "इनकम\n",
      "मासिक\n",
      "बीती\n",
      "हैवानियत\n",
      "नर्सरी\n",
      "कॉर्नर\n",
      "बुलवाया\n",
      "बीए\n",
      "वैद\n",
      "यातना\n",
      "प्\n",
      "फटकार\n",
      "जवाहर\n",
      "दूं\n",
      "मुकुट\n",
      "जीती\n",
      "अंधकार\n",
      "भोग\n",
      "स्वदेशी\n",
      "बागानों\n",
      "बिछाकर\n",
      "आमादा\n",
      "कोटा\n",
      "गिरा\n",
      "उद्धृत\n",
      "दोहरा\n",
      "नवाचार\n",
      "सेल्स\n",
      "बास्केटबॉल\n",
      "निम्नतम\n",
      "रिलीज\n",
      "धर्म-शास्त्र\n",
      "सर्किट\n",
      "अगाध\n",
      "अमीना\n",
      "दीनानाथ\n",
      "अनूठे\n",
      "फ्रेंड\n",
      "पकड़\n",
      "योगियों\n",
      "दूधिया\n",
      "चाईबासा\n",
      "चूर-चूर\n",
      "एफडीए\n",
      "नरेगा\n",
      "जुड़ीं\n",
      "हिमेश\n",
      "चिकित्सा\n",
      "प्रलय\n",
      "कबाडी\n",
      "धक्का\n",
      "बांधा\n",
      "देशवासियों\n",
      "बीसियों\n",
      "सदाशिव\n",
      "आधे\n",
      "थमने\n",
      "विज्ञप्ति\n",
      "रहत\n",
      "कामनाएँ\n",
      "स्टीक\n",
      "मेड़ों\n",
      "आना\n",
      "किसी\n",
      "नच\n",
      "गालियों\n",
      "मीथेन\n",
      "देशो\n",
      "लूँगा\n",
      "टेलीग्राफ\n",
      "स्वाभिमान\n",
      "फैजल\n",
      "सुनाकर\n",
      "झाड़ियों\n",
      "परदा\n",
      "जैव\n",
      "गाया\n",
      "नाते-रिश्ते\n",
      "शीतलता\n",
      "ख्यात\n",
      "तुम्ही\n",
      "रैली\n",
      "एक्टिविस्ट\n",
      "लंबा\n",
      "निष्काम\n",
      "रिवाज\n",
      "थो\n",
      "पग\n",
      "पट्टे\n",
      "अलापा\n",
      "विक्टोरिया\n",
      "सुनिए\n",
      "दृष्टिगोचर\n",
      "पुर\n",
      "ढक्कन\n",
      "New\n",
      "धंधे\n",
      "फ़रवरी\n",
      "पीथमपुर\n",
      "आकंठ\n",
      "मेरे\n",
      "मांगीलाल\n",
      "पित्त\n",
      "रत्ना\n",
      "मायूस\n",
      "थोडी़\n",
      "बन्द\n",
      "सिद्धी\n",
      "पि\n",
      "वक्ष\n",
      "टेलीविज़न\n",
      "समर्पित\n",
      "ढूँढ़ने\n",
      "मेन्यू\n",
      "जोल\n",
      "पुर्व\n",
      "स्थितियाँ\n",
      "डायरी\n",
      "सम्बंध\n",
      "उलझी\n",
      "पतली\n",
      "तख्ती\n",
      "संधू\n",
      "हील\n",
      "साईकिल\n",
      "राष्ट्रपतियों\n",
      "तोडा\n",
      "देनेवालों\n",
      "थोथा\n",
      "लगाते\n",
      "नापते\n",
      "सप्ताह\n",
      "देती\n",
      "प्रतिरोधक\n",
      "अजवाइन\n",
      "अंतरजाल\n",
      "पणी\n",
      "रोमांस\n",
      "कारन\n",
      "मधुबाला\n",
      "न्यारा\n",
      "बंगलुरू\n",
      "लिखकर\n",
      "गोदियाल\n",
      "स्वागत\n",
      "जर्सी\n",
      "मेडीकल\n",
      "मुद्दे\n",
      "प्लाट\n",
      "वेल्स\n",
      "नारा\n",
      "फ़ेसबुक\n",
      "अशांत\n",
      "किट\n",
      "कृतियों\n",
      "रिफंड\n",
      "प्रखर\n",
      "जिलो\n",
      "करवाएंगे\n",
      "सुलेमान\n",
      "जाते-जाते\n",
      "बेटों\n",
      "बेनेगल\n",
      "पदार्पण\n",
      "कीजिएगा\n",
      "संवेदन\n",
      "जाऊ\n",
      "वीकार\n",
      "धक\n",
      "कुमार\n",
      "गठीला\n",
      "सम्बंधों\n",
      "बहुत\n",
      "कपास\n",
      "एसीपी\n",
      "बोलो\n",
      "सिक्ख\n",
      "पत्रिकाएँ\n",
      "हममे\n",
      "मानवीय\n",
      "चलायें\n",
      "मनोरन्जन\n",
      "सुजाता\n",
      "करतूतें\n",
      "देखभालबैठक\n",
      "खंडेलवाल\n",
      "चार्ट\n",
      "टोंक\n",
      "खोजबीन\n",
      "भारतीयता\n",
      "वैष्णव\n",
      "बसंती\n",
      "सेलिना\n",
      "ताव\n",
      "मैग्जीन\n",
      "क्यूँ\n",
      "पढूंगा\n",
      "पारदर्शी\n",
      "आतिथ्य\n",
      "पहुंचें\n",
      "भून\n",
      "जटिलता\n",
      "Content\n",
      "अंदाज़ा\n",
      "आलोचकों\n",
      "Hits\n",
      "पीसीसी\n",
      "गिद्ध\n",
      "सौर\n",
      "Please\n",
      "पढ़िए\n",
      "उतावली\n",
      "मूकदर्शक\n",
      "लायी\n",
      "पूर्णतः\n",
      "शुरूआत\n",
      "ब्लॉगरी\n",
      "जायज\n",
      "वन्दे\n",
      "बदलना\n",
      "हीरोइन\n",
      "महाभारत\n",
      "रसास्वादन\n",
      "द्वार\n",
      "असमर्थ\n",
      "मुक़ाबला\n",
      "बांका\n",
      "धमकियों\n",
      "प्रेयसी\n",
      "आश\n",
      "गाँधी\n",
      "सेलिब्रिटीज\n",
      "सोचिये\n",
      "सहनशक्ति\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000,3000):\n",
    "    print(id2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1646555"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 0\n",
    "for key, value in vocabulary.items():\n",
    "    num_tokens += value\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = []\n",
    "for line in tokenized_hindi:\n",
    "    c = ' '.join(line)\n",
    "    concatenated.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'और अब कोई जीने में जीना थोड़े ही है दिन पूरे करने हैं UNK'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('hindi_small_concat.txt', \"wb\")\n",
    "for line in concatenated:\n",
    "    string_for_output = (line + '\\n').encode('utf8', 'replace')\n",
    "    fw.write(string_for_output)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'भारी हिमपात के समय यहां पर ### फीट बर्फ की मोटी परत जम जाती है'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "import os\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x7fa0b18f0748>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer.word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26996"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.texts_to_sequences(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96, 11936, 2, 61, 109, 651, 1187, 11]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 26997\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 1542713\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for line in concatenated:\n",
    "\tencoded = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(encoded)):\n",
    "\t\tsequence = encoded[:i+1]\n",
    "\t\tsequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-528d1798d1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# one hot encode outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mrepresentation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([3882, 255, 398, 4, 971, 503, 28, 71, 18298, 6, 2632, 5, 1380, 503, 120, 3, 7, 398, 4, 327, 2108, 1125, 525, 315, 6, 971, 13035, 838, 916, 464, 3]),\n",
       "       list([96, 11936, 2, 61, 109, 651, 1187, 11]),\n",
       "       list([5544, 1556, 1990, 115, 27, 766, 1, 9, 9]), ...,\n",
       "       list([47, 13, 1106, 57, 999]), list([1631, 9, 9, 8, 9, 5696, 12]),\n",
       "       list([65, 1, 256, 887, 22, 69, 756, 180, 5, 7882, 215])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 1, 50)             1349850   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26997)             1376847   \n",
      "=================================================================\n",
      "Total params: 2,746,897\n",
      "Trainable params: 2,746,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_3 to have shape (None, 26997) but got array with shape (99999, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-9b4ad257b801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1419\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1420\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have shape (None, 26997) but got array with shape (99999, 1)"
     ]
    }
   ],
   "source": [
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X, y, epochs=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
